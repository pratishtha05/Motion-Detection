import cv2

# Start the camera (use 0 for the default camera)
cap = cv2.VideoCapture(0)

# Read the first two frames from the camera
ret, frame1 = cap.read()
ret, frame2 = cap.read()

while True:
    # Calculate the absolute difference between consecutive frames
    diff = cv2.absdiff(frame1, frame2)
    
    # Convert to grayscale
    gray = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)
# Apply GaussianBlur to reduce noise and smooth the image
    blur = cv2.GaussianBlur(gray, (5, 5), 0)
    
    # Apply threshold to convert the blurred image to binary (black and white)
    _, thresh = cv2.threshold(blur, 20, 255, cv2.THRESH_BINARY)
    
    # Dilate the thresholded image to fill in holes and make the contours more solid
    dilated = cv2.dilate(thresh, None, iterations=3)
    
    # Find contours in the dilated image
    contours, _ = cv2.findContours(dilated, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
    
    for contour in contours:
        # Get the bounding box coordinates around the contour
        x, y, w, h = cv2.boundingRect(contour)
        
        # Filter out small movements (adjust the contour area threshold as needed)
        if cv2.contourArea(contour) < 5000:  # You can tweak this threshold
            continue
# Draw a rectangle around the detected motion
        cv2.rectangle(frame1, (x, y), (x + w, y + h), (0, 255, 0), 3)
        
        # Put text on the screen indicating "Movement"
        cv2.putText(frame1, "Movement", (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 3)
    
    # Show the video frame with the rectangle on the detected motion
    cv2.imshow('Motion Detection', frame1)
    
    # Update the frames for the next iteration
    frame1 = frame2
    ret, frame2 = cap.read()

    # Exit the loop if the user presses the 'q' key
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break
# Release the camera and close the windows
cap.release()
cv2.destroyAllWindows()
